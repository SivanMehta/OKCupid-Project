---
author: "35-315 Group 24"
output: 
  html_document:
    toc:  true
    toc_float:  true
---

```{r, warning=FALSE, echo=FALSE, message=FALSE}
library(ggplot2)
library(plotly)
library(tm)
library(wordcloud)

# load in data
if(!file.exists("sample.csv"))
{
    source("preprocess.r")
}
profiles <- read.csv("sample.csv")
```

# Sentiment Analysis

### Graph 1. Word Count vs. Sentiment

```{r, warning=FALSE, fig.width = 12}
ggplot(subset(profiles, polarity < 2 & wc < 500)) + 
            geom_point(aes(x = polarity, y = wc)) + 
            ggtitle("Word Count vs. Sentiment")
```

In this graph, we are graphing the continuous variables `polarity` and `wc`, or word count, which were both generated. The `wc` variable was generated by preprocessing the `essay0` variable in the dataset with the following code to generate the total number of words in the provided string:

```{r, eval = FALSE}
profiles$wc <- sapply(strsplit(as.character(profiles$essay0), " "), length)
```

To generate the `polarity` value we took the existing dataset and preprocessed it using the following code:

```{r, eval = FALSE}
library(qdap)
sample <- profiles[sample(nrow(profiles), 2000), ]
sample$polarity <- polarity(sample$essay0)$all$polarity
```

Because the `polarity` function from the [`qdap`](https://cran.r-project.org/web/packages/qdap/index.html) package takes a long time, we had to take a random sample of 2000 profiles from the dataset. This function simply takes a string and returns the polarity of the text, or simply how positive or negative the sentiment of the text is. Both the preprocessing for `polarity` and `wc` were done in a `preprocess.r` file that was provided in the final project.

We took a subset here simply to leave out what we saw as outliers. This helps "zoom" in the graph to the more interesting pieces, and helps make the group structure easier to see.

In this graph, we see `wc` on the vertical axis and `polarity` on the horizontal axis. The black coloring of the points and the size of the points are all the same and have no actual bearing. An interesting feature that certainly stands out in this graph is the clear groups that form along lines that look like variations of a $y=\frac{ 1 }{ x }$ kind of curve. Upon further analysis, it would be interesting to see if these groups correspond to as they don't correspond to any of the categorical variables provided in the dataset

### Graph 2. Age vs. Income

```{r, fig.width = 12}
correlation <- cor(profiles$income, profiles$age, use = "na.or.complete") ** 2
mytext <- paste("Age vs. Income with", "r^2 = ", correlation, ", colored by sentiment")
wanted <- subset(profiles, income < 250000 & income > 0)
        
ggplot(wanted) + 
    aes(x = age, y = income) + 
    geom_point(aes(colour = polarity)) + 
    scale_colour_gradientn(colours=c("#FF0000", "#ffffff", "#440088","#0000FF")) + 
    geom_smooth(method = "lm") + 
    ggtitle(mytext)
```

Using the preprocessed `polarity` variable, I then tried to use it to explore the relationship between `age` and `income`. Additionally, I plotted a smoothing line to see if there was an overall trend that could be teased out. While one would presume that older people would be older simply because they have advanced further in their career, this hypothesis can only losely be corroborated.

We can actually check a linear regression model with the following command:

```{r}
summary(lm(wanted$age ~ wanted$income))
```

Because our p-value for the slope is < .05, we reject the null hypothesis that this slope is not zero. However, just looking at the graph demonstrates that this model is incredibly inaccurate because of the large variation in the `income` variable. One limitation of this type of visualization is that while age was reported by year, income was not nearly as granular, offering only 13 distinct levels, with a vast majority not reporting at all, which is why we included `income > 0` in our graphs and analysis.

When including the `polarity` variable by coloring by a continuous color scale, we fail to see any ascertainable trends. There is no indication that sentiment has any relation to the age or the income of the profile. These claims can be corroborated by the following graphs having relatively flat `geom_smooth` geometries, indicating that there is little correlation between `polarity` and either `age` or `income`.

```{r, warning=FALSE, fig.width = 12}
base <- ggplot(wanted) +  # data
        geom_point() +    # scatterplot
        geom_smooth() +   # smoothing line
        aes(y = polarity) # polarity on the y-axis

base + aes(x = age)
base + aes(x = income)
```

> Created, presented, and described by Sivan Mehta

# Plot Two Categorical

```{r, fig.height=6, fig.width=12}

plotTwoCategorical = function(var1, var2, df=profiles){
  var1.c = c()
  var2.c= c()
  
  # data frame creation
  var1.list = unique(df[[var1]])
  var2.list = unique(df[[var2]])
  for(i in unique(df[[var1]])){
    var1.c = c(var1.c, rep(i,length(unique(df[[var2]]))))
  }
  var2.c = rep(var2.list,length(var1.list))
  temp.df = as.data.frame(as.character(var1.c))
  colnames(temp.df) = "var.1"
  temp.df$var.2 = as.character(var2.c)
  temp.df$var.1 = as.character(temp.df$var.1)
  temp.df$count = rep(0, nrow(temp.df))
  temp.df$freq = rep(0,nrow(temp.df))
  for(i in 1:nrow(temp.df)){
    temp.df$count[i] = nrow(subset(df, df[[var1]] == temp.df$var.1[i] & 
                                     df[[var2]] == temp.df$var.2[i]))
  }
  for(i in 1:nrow(temp.df)){
    temp.df$freq[i] = temp.df$count[i] / sum(temp.df$count[which(temp.df$var.1 == temp.df$var.1[i])]) 
  }
  
  plot1 = ggplot(temp.df) + geom_point(aes(x=var.1,y=var.2, size = freq)) +
          scale_size(range = c(0, 25)) +
            ggtitle(paste("Proportion Breakdown of ",gsub("_", " ", var1),
                          " and ", gsub("_", " ", var2), sep="")) + 
            labs(x=gsub("_", " ", var1),y=gsub("_", " ", var2))
  ggplotly()
}

plotTwoCategorical("body_type","drinks",profiles)
```

This allows for an easy and early data analysis of different relationships that we may want to examine. For example, looking at drinking habits based on body types yields two interesting relationships: a higher proportion od desperate drinkers are jacked or used up than any other body type. Further, people who consider themselves above average in terms of weight (full figured, a little extra) tend to drink less often (a higher proportion of them report not drinking at all). 

The graph is used as a tool to determine marginal distributions of any two categorical variables in the data. It allows for a simpler comparison along the x-axis, where each variable on the x-axis sums to 1. This is effectively a stacked bar chart for proportions, but since each dot is spaced out equally, we can compare across the y-axis too. This was done by creating a a dataframe of the length of variable1*variable2, then counting the occurances of each intersection. The only manipulation of the data required is to convert all the factor-level data into strings via as.character.

> Created, presented, and described by Patrick Chang

# Word Clouds

```{r}

getTraitsCloud = function(dataset){
  corpus = Corpus(VectorSource(dataset$essay9))
  plaintext = tm_map(corpus, PlainTextDocument)
  crude_plain <- tm_map(plaintext, removePunctuation)
  crude_plain <- tm_map(crude_plain, removeWords, stopwords('english'))
  crude_plain <- tm_map(crude_plain, stemDocument)
  wordcloud(crude_plain, max.words = 100, random.order = FALSE)
}


getTraitsCloud(profiles[which(profiles$body_type == "fit"),])
```

This looks at a word cloud of what traits fit people desire in their partners (done by parsing essay9). While there are a few words what do not correspond to traits, we see that most fit people in our sample want partners who are honest, fun, humorous, genuine, active, and adventurous. While not very telling by itself, this lends more information by telling us what traits potential partners of each body type are looking for. 

This was created with the wordCloud library. We converted essay9 ("you should message me if") into a plaintext corpus, then parsed it to remove punctuation and some common stopwords. It then returns a word cloud of length 100, as there are multiple words that do not give information, but are not coded as stopwords. There is no manipulation required for generating this graphic. 

> Created, presented, and described by Patrick Chang

# Livestyle vs. Age

> Created, presented, and described by Joyce Sun

# Traits Offered vs. Demanded

> Created, presented, and described by Joyce Sun

# Maps

> Created, presented, and described by Suvrath Penmetcha

# Mosaic Plot

> Created, presented, and described by Suvrath Penmetcha
